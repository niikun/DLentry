{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN1f2A8nCaiVHfgg6jX+/Jn",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/niikun/DLentry/blob/main/lanchain_chains.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Gw0dT6pq84XV"
      },
      "outputs": [],
      "source": [
        "!pip install openai"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from google.colab import userdata"
      ],
      "metadata": {
        "id": "c4e243Ni89OL"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "os.environ[\"OPENAI_API_KEY\"] = userdata.get('OPENAI_API_KEY')"
      ],
      "metadata": {
        "id": "g4thqgox9GGP"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install langchain"
      ],
      "metadata": {
        "id": "GouGNl0u9YGv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.chat_models import ChatOpenAI\n",
        "from langchain.output_parsers import PydanticOutputParser\n",
        "from langchain.prompts import PromptTemplate\n",
        "from pydantic import BaseModel, Field"
      ],
      "metadata": {
        "id": "FwoiVfj090Eu"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chat = ChatOpenAI(model_name=\"gpt-3.5-turbo\",temperature=0)\n",
        "cot_template= \"\"\"以下の質問に回答してください。\n",
        "質問:{question}\n",
        "ステップバイステップで考えてください。\n",
        "\"\"\"\n",
        "\n",
        "cot_prompt = PromptTemplate(template=cot_template,\n",
        "                            input_variables=[\"question\"],\n",
        "                            )"
      ],
      "metadata": {
        "id": "SqPugtCfI9MN"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain import LLMChain"
      ],
      "metadata": {
        "id": "XqedCmtUI9a9"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cot_chain = LLMChain(llm=chat,prompt=cot_prompt)\n",
        "cot_chain.run(question=\"私は10個のリンゴを買いました。隣人に2つ、友達に2個渡しました。それから5つリンゴを買って、1つ食べました。残りは何個ですか？\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "id": "e6y-qhwcKyQ0",
        "outputId": "0f64934d-4dcb-4d9a-9d53-66a5a226eab3"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'1. 最初に10個のリンゴを買いました。\\n2. 隣人に2つ渡しましたので、残りは10 - 2 = 8個です。\\n3. 友達に2個渡しましたので、残りは8 - 2 = 6個です。\\n4. さらに5つリンゴを買いましたので、残りは6 + 5 = 11個です。\\n5. 1つリンゴを食べましたので、残りは11 - 1 = 10個です。\\n\\nしたがって、残りのリンゴは10個です。'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "ZuDKgREPI7m3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "summarize_template = \"\"\"以下の文章を結論だけ、一言で要約してください.\n",
        "{input}\n",
        "\"\"\"\n",
        "\n",
        "sum_prompt=PromptTemplate(template=summarize_template,input_variables=[\"input\"])\n",
        "\n",
        "sumchain=LLMChain(llm=chat,prompt=sum_prompt)"
      ],
      "metadata": {
        "id": "Rfla1i1lLGIQ"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sumchain.run(input=\"1. 最初に10個のリンゴを買いました。\\n2. 隣人に2つ渡しましたので、残りは10 - 2 = 8個です。\\n3. 友達に2個渡しましたので、残りは8 - 2 = 6個です。\\n4. さらに5つリンゴを買いましたので、残りは6 + 5 = 11個です。\\n5. 1つリンゴを食べましたので、残りは11 - 1 = 10個です。\\n\\nしたがって、残りのリンゴは10個です\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "hwt-43oqLGOx",
        "outputId": "c195bfd5-5dc4-43e7-bda4-5883dffe0c63"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'残りのリンゴは10個。'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.chains import SimpleSequentialChain\n",
        "cot_sum_chain = SimpleSequentialChain(chains=[cot_chain,sumchain])\n",
        "result=cot_sum_chain(\"私は10個のリンゴを買いました。隣人に2つ、友達に2個渡しました。それから5つリンゴを買って、1つ食べました。残りは何個ですか？\")\n",
        "print(result[\"output\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QOSgzA9ALGWv",
        "outputId": "0736e168-4df1-4419-eb38-c2d99fca32da"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "最終的に残るリンゴは10個です。\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# class Recipe(BaseModel):\n",
        "#   ingredients:list[str]=Field(description=\"ingredients of the dish\")\n",
        "#   steps:list[str]=Field(description=\"steps to make the dish\")\n",
        "\n",
        "# output_parser = PydanticOutputParser(pydantic_object=Recipe)\n",
        "# # format_instructions=output_parser.get_format_instructions()\n",
        "\n",
        "# template = \"\"\"あなたは{genre}料理のプロです。レシピを考えてください。\n",
        "# {format_instructions}\n",
        "# 料理名:{dish}\n",
        "# \"\"\"\n",
        "\n",
        "# prompt = PromptTemplate(\n",
        "#     template=template,\n",
        "#     input_variables=[\"dish\",\"genre\"],\n",
        "#     partial_variables={\"format_instructions\":output_parser.get_format_instructions()})\n",
        "\n",
        "# chat = ChatOpenAI(model_name=\"gpt-3.5-turbo\",temperature=0)"
      ],
      "metadata": {
        "id": "HvegqC9S-hA4"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# from langchain import LLMChain\n",
        "# chain = LLMChain(prompt=prompt,llm=chat,output_parser=output_parser)\n",
        "\n",
        "# recipe = chain.run(dish=\"カレー\",genre=\"和食\")\n",
        "# print(type(recipe))\n",
        "# print(recipe)"
      ],
      "metadata": {
        "id": "VqsR-Fp9DsR0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "xm6ISYbZErYn"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}